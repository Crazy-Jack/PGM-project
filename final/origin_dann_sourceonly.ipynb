{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.backends.cudnn as cudnn\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import logging.handlers\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--batch_size BATCH_SIZE] [--learning_rate LEARNING_RATE] [--momentum MOMENTUM] [--gpu_num GPU_NUM]\n",
      "                             [--seed SEED] [--save_path SAVE_PATH] [--subfolder SUBFOLDER] [--wtarget WTARGET]\n",
      "                             [--model_save_period MODEL_SAVE_PERIOD] [--epochs EPOCHS] [--dann_weight DANN_WEIGHT]\n",
      "                             [--start_origin_dann START_ORIGIN_DANN]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /home/tianqinl/.local/share/jupyter/runtime/kernel-cceb65dc-79f9-462c-9442-12406ea899aa.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tianqinl/anaconda3/envs/pgm/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3339: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='Domain adaptation')\n",
    "parser.add_argument(\"--batch_size\", type=int, default=\"400\", help=\"batch size\")\n",
    "parser.add_argument(\"--learning_rate\", type=float, default=1e-3, help=\"learning rate\")\n",
    "parser.add_argument(\"--momentum\", type=float, default=0.5, help=\"momentum\")\n",
    "parser.add_argument(\"--gpu_num\", type=int, default=0, help=\"gpu num\")\n",
    "parser.add_argument(\"--seed\", type=int, default=123, help=\"munually set seed\")\n",
    "parser.add_argument(\"--save_path\", type=str, default=\"../train_related\", help=\"save path\")\n",
    "parser.add_argument(\"--subfolder\", type=str, default='domain_origin_dann_svhn_to_mnist', help=\"subfolder name\")\n",
    "parser.add_argument(\"--wtarget\", type=float, default=0.7, help=\"target weight\")\n",
    "parser.add_argument(\"--model_save_period\", type=int, default=2, help=\"save period\")\n",
    "parser.add_argument(\"--epochs\", type=int, default=2000, help=\"label shuffling\")\n",
    "parser.add_argument(\"--dann_weight\", type=float, default=1, help=\"weight for label shuffling\")\n",
    "parser.add_argument(\"--start_origin_dann\", type=int, default=100, help=\"when to start shuffling\")\n",
    "parser.add_argument(\"--use_gpu\", type=int, default=0, help=\"whether using gpu to train\")\n",
    "\n",
    "\n",
    "args = parser.parse_args()\n",
    "# snap shot of py file and command\n",
    "python_file_name = sys.argv[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# local only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # local only\n",
    "# class local_args:\n",
    "#     def __init__(self, **entries):\n",
    "#         self.__dict__.update(entries)\n",
    "        \n",
    "# args = local_args(**{\n",
    "#     'batch_size': 400,\n",
    "#     'learning_rate': 1e-3,\n",
    "#     'momentum': 0.5,\n",
    "#     'gpu_num': 0,\n",
    "#     'seed': 123,\n",
    "#     'save_path': \"../train_related\",\n",
    "#     'epochs': 2,\n",
    "#     'subfolder': \"testing\",\n",
    "#     'wtarget': 0.7,\n",
    "#     'dann_weight': 1,\n",
    "#     'model_save_period': 2,\n",
    "#     'start_origin_dann': 0,\n",
    "#     'use_gpu': 0,\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "if args.use_gpu == 1 and torch.cuda.is_available():\n",
    "    device = torch.device('cuda:{}'.format(args.gpu_num))\n",
    "else:\n",
    "    device = 'cpu'\n",
    "print(device)\n",
    "# seed\n",
    "torch.manual_seed(args.seed)\n",
    "torch.cuda.manual_seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "cudnn.deterministic = True\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_sub_folder = args.subfolder + '/origin_dann_weight_%f_learningrate_%f'%(args.dann_weight, args.learning_rate)\n",
    "save_folder = os.path.join(args.save_path, model_sub_folder)\n",
    "if not os.path.exists(save_folder):\n",
    "    os.makedirs(save_folder)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size: 400\n",
      "learning_rate: 0.001\n",
      "momentum: 0.5\n",
      "gpu_num: 0\n",
      "seed: 123\n",
      "save_path: ../train_related\n",
      "epochs: 2\n",
      "subfolder: testing\n",
      "wtarget: 0.7\n",
      "dann_weight: 1\n",
      "model_save_period: 2\n",
      "start_origin_dann: 0\n",
      "use_gpu: 0\n",
      "Training Save Path: ../train_related/testing/origin_dann_weight_1.000000_learningrate_0.001000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "logfile_path = os.path.join(save_folder, 'logfile.log')\n",
    "if os.path.isfile(logfile_path):\n",
    "    os.remove(logfile_path)\n",
    "    \n",
    "file_log_handler = logging.FileHandler(logfile_path)\n",
    "logger.addHandler(file_log_handler)\n",
    "\n",
    "stdout_log_handler = logging.StreamHandler(sys.stdout)\n",
    "logger.addHandler(stdout_log_handler)\n",
    "\n",
    "attrs = vars(args)\n",
    "for item in attrs.items():\n",
    "    logger.info(\"%s: %s\"%item)\n",
    "logger.info(\"Training Save Path: {}\".format(save_folder))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_trainset = datasets.MNIST(root='../data', train=True, download=True, transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_testset = datasets.MNIST(root='../data', train=False, download=True, transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ../data/train_32x32.mat\n"
     ]
    }
   ],
   "source": [
    "svhn_trainset = datasets.SVHN(root='../data', split='train', download=True, transform=torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.Resize((28, 28)),\n",
    "                    torchvision.transforms.Grayscale(num_output_channels=1),\n",
    "                    torchvision.transforms.ToTensor(),\n",
    "                    torchvision.transforms.Normalize([0.5], [0.5])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ../data/test_32x32.mat\n"
     ]
    }
   ],
   "source": [
    "svhn_testset = datasets.SVHN(root='../data', split='test', download=True, transform=torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.Resize((28, 28)),\n",
    "                    torchvision.transforms.Grayscale(num_output_channels=1),\n",
    "                    torchvision.transforms.ToTensor(),\n",
    "                    torchvision.transforms.Normalize([0.5], [0.5])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # mnist\n",
    "# train_mnist_loader = DataLoader(mnist_trainset, batch_size=args.batch_size, shuffle=True)\n",
    "# test_mnist_loader = DataLoader(mnist_testset, batch_size=args.batch_size, shuffle=True)\n",
    "# examples = enumerate(test_mnist_loader)\n",
    "# batch_idx, (example_data, example_targets) = next(examples)\n",
    "\n",
    "\n",
    "# fig = plt.figure()\n",
    "# for i in range(6):\n",
    "#   plt.subplot(2,3,i+1)\n",
    "#   plt.tight_layout()\n",
    "#   plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "#   plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n",
    "#   plt.xticks([])\n",
    "#   plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# svhn\n",
    "train_svhn_loader = DataLoader(svhn_trainset, batch_size=args.batch_size, shuffle=True)\n",
    "test_svhn_loader = DataLoader(svhn_trainset, batch_size=args.batch_size, shuffle=True)\n",
    "examples = enumerate(train_svhn_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "    plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload data\n",
    "train_mnist_loader = DataLoader(mnist_trainset, batch_size=args.batch_size, shuffle=True)\n",
    "test_mnist_loader = DataLoader(mnist_testset, batch_size=args.batch_size, shuffle=True)\n",
    "train_svhn_loader = DataLoader(svhn_trainset, batch_size=args.batch_size, shuffle=True)\n",
    "test_svhn_loader = DataLoader(svhn_trainset, batch_size=args.batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process data for cancat with source and target label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConcatDataset(Dataset):\n",
    "    def __init__(self, x, y, mode='mnist'):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.len = self.x.shape[0]\n",
    "        self.mode = mode\n",
    "        if self.mode == 'mnist':\n",
    "            self.transform = torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])\n",
    "        elif self.mode == 'svhn':\n",
    "            self.transform = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.Resize((28, 28)),\n",
    "                    torchvision.transforms.Grayscale(num_output_channels=1),\n",
    "                    torchvision.transforms.ToTensor(),\n",
    "                    torchvision.transforms.Normalize([0.5], [0.5])])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if self.mode == 'mnist':\n",
    "            img = Image.fromarray(self.x[index].numpy(), mode='L')\n",
    "            img = self.transform(img)\n",
    "        elif self.mode == 'svhn':\n",
    "            img = Image.fromarray(np.transpose(self.x[index], (1, 2, 0)))\n",
    "            img = self.transform(img)\n",
    "    \n",
    "        return img, self.y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "concat_mnist_train = ConcatDataset(mnist_trainset.data, torch.zeros(mnist_trainset.data.shape[0], dtype=torch.long), mode = 'mnist')\n",
    "concat_svhn_train = ConcatDataset(svhn_trainset.data, torch.ones(svhn_trainset.data.shape[0], dtype=torch.long), mode = 'svhn')\n",
    "\n",
    "\n",
    "adverial_dataset = torch.utils.data.ConcatDataset([concat_mnist_train, concat_svhn_train])\n",
    "# [i[1] for i in [adverial_dataset[m] for m in torch.randint(0, len(adverial_dataset), (100,))]]\n",
    "adverial_loader = DataLoader(adverial_dataset, batch_size=args.batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 30)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FNN(nn.Module):\n",
    "    def __init__(self, d_in, d_h1, d_h2, d_out, dp=0.2):\n",
    "        super(FNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(d_in, d_h1)\n",
    "        self.ln1 = nn.LayerNorm(d_h1)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.dropout1 = nn.Dropout(dp)\n",
    "        self.fc2 = nn.Linear(d_h1, d_h2)\n",
    "        self.ln2 = nn.LayerNorm(d_h2)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.dropout2 = nn.Dropout(dp)\n",
    "        self.fc3 = nn.Linear(d_h2, d_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.ln1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.ln2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def before_lastlinear(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.ln1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.ln2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.dropout2(x)\n",
    "        return x\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adversial_loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Adversial_loss, self).__init__()\n",
    "    \n",
    "    def forward(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "    elif type(m) == nn.LayerNorm:\n",
    "        torch.nn.init.normal_(m.weight, 1.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FNN(\n",
       "  (fc1): Linear(in_features=30, out_features=100, bias=True)\n",
       "  (ln1): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
       "  (relu1): ReLU(inplace=True)\n",
       "  (dropout1): Dropout(p=0.2, inplace=False)\n",
       "  (fc2): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (ln2): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
       "  (relu2): ReLU(inplace=True)\n",
       "  (dropout2): Dropout(p=0.2, inplace=False)\n",
       "  (fc3): Linear(in_features=100, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(args.seed)\n",
    "torch.cuda.manual_seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "\n",
    "encoder = Encoder().to(device)\n",
    "CNet = FNN(d_in=30, d_h1=100, d_h2=100, d_out=10, dp=0.2).to(device)\n",
    "DomainCNet = FNN(d_in=30, d_h1=100, d_h2=100, d_out=2, dp=0.2).to(device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "optimizerEncoder = optim.Adam(encoder.parameters(), lr=args.learning_rate)\n",
    "optimizerCNet = optim.Adam(CNet.parameters(), lr=args.learning_rate)\n",
    "optimizerDomainCNet = optim.Adam(DomainCNet.parameters(), lr=args.learning_rate)\n",
    "\n",
    "criterion_classifier = nn.CrossEntropyLoss().to(device)\n",
    "# criterion_adverisal = \n",
    "\n",
    "encoder.apply(weights_init)\n",
    "CNet.apply(weights_init)\n",
    "DomainCNet.apply(weights_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'logger' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-83e62bd66899>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtarget_test_acc_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Started Training'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'logger' is not defined"
     ]
    }
   ],
   "source": [
    "target_acc_label_ = []\n",
    "source_acc_ = []\n",
    "source_test_acc_ = []\n",
    "target_test_acc_ = []\n",
    "\n",
    "logger.info('Started Training')\n",
    "\n",
    "\n",
    "for epoch in range(args.epochs):\n",
    "    # update classifier\n",
    "    # on target domain mnist\n",
    "    CNet.train()\n",
    "    encoder.train()\n",
    "    source_acc = 0.0\n",
    "    num_datas = 0.0\n",
    "    for batch_id, (source_x, source_y) in tqdm(enumerate(train_svhn_loader), total=len(train_svhn_loader)):\n",
    "        optimizerCNet.zero_grad()\n",
    "        optimizerEncoder.zero_grad()\n",
    "        source_x = source_x.to(device).float()\n",
    "        source_y = source_y.to(device)\n",
    "        num_datas += source_x.size(0)\n",
    "        source_x_embedding = encoder(source_x)\n",
    "        pred = CNet(source_x_embedding)\n",
    "        source_acc += (pred.argmax(-1) == source_y).sum().item()\n",
    "        loss = criterion_classifier(pred, source_y)\n",
    "        loss.backward()\n",
    "        optimizerCNet.step()\n",
    "        optimizerEncoder.step()\n",
    "        \n",
    "        \n",
    "    source_acc = source_acc / num_datas\n",
    "    source_acc_.append(source_acc)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # on target domain svhn\n",
    "#     target_acc = 0.0\n",
    "#     num_datas = 0.0\n",
    "#     CNet.train()\n",
    "#     encoder.train()\n",
    "\n",
    "#     for batch_id, (target_x, target_y) in tqdm(enumerate(train_svhn_loader), total=len(train_svhn_loader)):\n",
    "#         optimizerCNet.zero_grad()\n",
    "#         optimizerEncoder.zero_grad()\n",
    "#         target_x = target_x.to(device).float()\n",
    "#         target_y = target_y.to(device)\n",
    "#         num_datas += target_x.size(0)\n",
    "#         target_x_embedding = encoder(target_x)\n",
    "#         pred = CNet(target_x_embedding)\n",
    "#         target_acc += (pred.argmax(-1) == target_y).sum().item()\n",
    "#         loss = criterion_classifier(pred, target_y)\n",
    "#         loss.backward()\n",
    "#         optimizerCNet.step()\n",
    "#         optimizerEncoder.step()\n",
    "        \n",
    "    \n",
    "#     target_acc = target_acc / num_datas\n",
    "#     target_acc_label_.append(target_acc)\n",
    "    \n",
    "    \n",
    "    # DANN shuffle\n",
    "    if epoch >= args.start_origin_dann:\n",
    "        DomainCNet.train()\n",
    "        encoder.train()\n",
    "        num_datas = 0.0\n",
    "        for batch_id, (adv_x, adv_y) in tqdm(enumerate(adverial_loader), total=len(adverial_loader)):\n",
    "            # encoder loss\n",
    "            optimizerCNet.zero_grad()\n",
    "            optimizerEncoder.zero_grad()\n",
    "            adv_x = adv_x.to(device).float()\n",
    "            adv_y = adv_y.to(device)\n",
    "            num_datas += adv_x.size(0)\n",
    "            adv_x_embedding = encoder(adv_x)\n",
    "            pred = DomainCNet(adv_x_embedding)\n",
    "            # adv_acc += (pred.argmax(-1) == adv_y).sum().item()\n",
    "            loss = - args.dann_weight * criterion_classifier(pred, adv_y)\n",
    "            loss.backward()\n",
    "            optimizerEncoder.step()\n",
    "\n",
    "        for batch_id, (adv_x, adv_y) in tqdm(enumerate(adverial_loader), total=len(adverial_loader)):\n",
    "            # domain layer loss\n",
    "            DomainCNet.train()\n",
    "            encoder.train()\n",
    "            optimizerCNet.zero_grad()\n",
    "            optimizerEncoder.zero_grad()\n",
    "            adv_x = adv_x.to(device).float()\n",
    "            adv_y = adv_y.to(device)\n",
    "            adv_x_embedding = encoder(adv_x)\n",
    "            pred = DomainCNet(adv_x_embedding)\n",
    "            # adv_acc += (pred.argmax(-1) == adv_y).sum().item()\n",
    "            loss_adv = args.dann_weight * criterion_classifier(pred, adv_y)\n",
    "            loss_adv.backward()\n",
    "            optimizerDomainCNet.step()    \n",
    "\n",
    "    \n",
    "    \n",
    "    # eval on source   \n",
    "    source_test_acc = 0.0\n",
    "    num_datas = 0.0\n",
    "    CNet.eval()\n",
    "    encoder.eval()\n",
    "    \n",
    "    for batch_id, (source_x, source_y) in tqdm(enumerate(test_svhn_loader), total=len(test_svhn_loader)):\n",
    "        optimizerCNet.zero_grad()\n",
    "        optimizerEncoder.zero_grad()\n",
    "        source_x = source_x.to(device).float()\n",
    "        source_y = source_y.to(device)\n",
    "        num_datas += source_x.size(0)\n",
    "        source_x_embedding = encoder(source_x)\n",
    "        pred = CNet(source_x_embedding)\n",
    "        source_test_acc += (pred.argmax(-1) == source_y).sum().item()\n",
    "        \n",
    "    source_test_acc = source_test_acc / num_datas\n",
    "    source_test_acc_.append(source_test_acc)\n",
    "    \n",
    "    # eval on target \n",
    "    num_datas = 0.0\n",
    "    target_test_acc = 0.0\n",
    "    for batch_id, (target_x, target_y) in tqdm(enumerate(test_mnist_loader), total=len(test_mnist_loader)):\n",
    "        optimizerCNet.zero_grad()\n",
    "        optimizerEncoder.zero_grad()\n",
    "        target_x = target_x.to(device).float()\n",
    "        target_y = target_y.to(device)\n",
    "        num_datas += target_x.size(0)\n",
    "        target_x_embedding = encoder(target_x)\n",
    "        pred = CNet(target_x_embedding)\n",
    "        target_test_acc += (pred.argmax(-1) == target_y).sum().item()\n",
    "    \n",
    "    target_test_acc = target_test_acc / num_datas\n",
    "    target_test_acc_.append(target_test_acc)\n",
    "    \n",
    "    if epoch % args.model_save_period == 0:\n",
    "        torch.save(DomainCNet.state_dict(), os.path.join(save_folder, 'DomainCNet_%i.t7'%(epoch+1)))\n",
    "        torch.save(encoder.state_dict(), os.path.join(save_folder, 'encoder_%i.t7'%(epoch+1)))\n",
    "        torch.save(CNet.state_dict(), os.path.join(save_folder, 'CNet_%i.t7'%(epoch+1)))\n",
    "\n",
    "    \n",
    "    logger.info('Epochs %i: source train acc: %f; source test acc: %f; target test acc: %f'%(epoch+1, source_acc, source_test_acc, target_test_acc))\n",
    "    np.save(os.path.join(args.save_path, model_sub_folder, 'source_acc_.npy'),source_acc_)\n",
    "    np.save(os.path.join(args.save_path, model_sub_folder, 'source_test_acc_.npy'),source_test_acc_)\n",
    "    np.save(os.path.join(args.save_path, model_sub_folder, 'target_test_acc_.npy'),target_test_acc_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
